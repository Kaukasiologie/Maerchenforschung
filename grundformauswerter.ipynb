{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8bf159b",
   "metadata": {},
   "source": [
    "## grundformauswerter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9389e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import json\n",
    "from hilfsfunktoinen import sortiere_dana, lade_referenz_liste_aus_xsd\n",
    "\n",
    "from collections import Counter, defaultdict, deque\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b75d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abfrageparameter\n",
    "\n",
    "datei = 'gesamt_maerchen.xml'\n",
    "gesuchter_typ = '{\"AND\": [\"a563\"], \"NOT\": [\"a425A\"]}'\n",
    "haeufigkeit = '3'\n",
    "include_labeld = True\n",
    "\n",
    "# --- Beispiele ---\n",
    "# nur EINZELTYP ohne Kombination = Knoten mit Bogen\n",
    "# Typ = \"a707\"\n",
    "\n",
    "# Kombination : Knoten mit Bogen und/oder Kanten mit der Möglichkeit Kanten zu\n",
    "# filtrieren\n",
    "# Typ = {\"AND\": [\"a563\",\"a425A\"], \"OR\": [\"a300\"], \"NOT\": [\"a700\"], \"MODE\": \"OR\"}\n",
    "# Typ = {\"AND\": [\"a563\",\"a425A\"], \"OR\": [\"a300\"], \"MODE\": \"AND\"}\n",
    "\n",
    "# Falls Typ als Liste übergeben → automatisch zu {\"AND\": [...]} umwandeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "591d51d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typ(en) = {\"AND\": [\"a563\"], \"NOT\": [\"a425A\"]}\n",
      "Häufigkeit = 3\n",
      "Text-IDs:\n",
      "'zyx_cc_ddo_rus_76'\t'zyx_cc_ddo_rus_90'\t'zyx_cc_kva_rus_13'\n",
      "'zyx_cr_aqc_rus_17'\t'zyx_cr_aqc_rus_5'\t'zyx_cr_ava_rus_11'\n",
      "'zyx_cr_ava_rus_174'\n",
      "---------------------\n",
      "a563:F:ARMUT_beheben:rEHDem_rHHDew\n",
      "a563:h:ARMUT:rEHDem_rHHDew\n",
      "a563:F:ARMUT_beheben:rEHDem_rHHDew_+\n",
      "a563:F:Sorge_um_Potenzielle_Beute:rEHDem_rEHFez_rEHFgz\n",
      "a563:H:Sorge_um_Potenzielle_Beute:rEHDem_rEHFez_rEHFgz\n",
      "a563:H:PROVIANTPRODUZIERENDES_Zaubermittel_erhalten:rEHDem_rEHFez_rEHFgz\n",
      "a563:H:PROVIANTPRODUZIERENDES_Zaubermittel_einsetzen:rEHDem_rEHFgz_rHHDew\n",
      "a563:H:ARMUT_beheben:rEHDem_rEHFgz_rHHDew\n",
      "a563:H:PROVIANTPRODUZIERENDES_Zaubermittel_einsetzen:rEHDem_rEANem_rEHFgz\n",
      "a563:h:Umgang_mit_Gier_und_Neid:rEHDem_rEANem_rEHFgz\n",
      "a563:h:ANEIGNUNG:rEHDem_rEANem_rEHFgz\n",
      "a563:h:ARMUT:rEHDem_rHHDew_+\n",
      "a563:H:Auf_Hilfsquelle_zurückgreifen:rEHDem_rEHFez_rEHFgz\n",
      "a563:H:Gold_oder_GELDPRODUZIERENDES_Zaubermittel_erhalten:rEHDem_rEHFez_rEHFgz\n",
      "a563:H:Gold_oder_GELDPRODUZIERENDES_Zaubermittel_einsetzen:rEHDem_rEHFgz_rHHDew\n",
      "a563:H:Auf_Hilfsquelle_zurückgreifen:rEHDem_rEHFez_rEHFgZ\n",
      "a563:H:STRAFVOLLSTRUCKENDES_Zaubermittel_erhalten:rEHDem_rEHFez_rEHFgZ\n",
      "a563:H:STRAFVOLLSTRUCKENDES_Zaubermittel_einsetzen:rEHDem_rEANem_rEHFgZ\n",
      "a563:H:ANEIGNUNG_beheben:rEHDem_rEANem_rEHFgZ\n",
      "a563:H:ANEIGNUNG_beheben:rEHDem_rEANem_rEHFgZ_+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from hilfsfunktoinen import sortiere_dana, lade_referenz_liste_aus_xsd\n",
    "\n",
    "from collections import Counter, defaultdict, deque\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Falls Typ als Liste übergeben → automatisch zu {\"AND\": [...]} umwandeln\n",
    "\n",
    "def get_mode(Typ):\n",
    "    if isinstance(Typ, list):\n",
    "        Typ = {\"AND\": Typ}\n",
    "\n",
    "    # Standard-Mode, falls nicht angegeben\n",
    "    mode = Typ.get(\"MODE\", \"AND\").upper() if isinstance(Typ, dict) else \"AND\"\n",
    "    return mode\n",
    "\n",
    "def eindeutige_zeilen_erstellen(xml_database_name, typ_input, min_count):\n",
    "\n",
    "    min_count = int(min_count)\n",
    "    typ_input = json.loads(typ_input)\n",
    "\n",
    "    NS = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "    ROOT_NODE = ET.parse(f\"{xml_database_name}\").getroot()\n",
    "\n",
    "    mode = get_mode(typ_input)\n",
    "    REFERENZ_LISTE = lade_referenz_liste_aus_xsd(\"kf/vmf_d1.xsd\")\n",
    "\n",
    "    textid_to_typ = {}\n",
    "    for corp in ROOT_NODE.findall(\".//tei:teiCorpus\", NS):\n",
    "\n",
    "        for ganze in corp.findall(\".//tei:TEI\", NS):\n",
    "\n",
    "            for text in ganze.findall(\".//tei:text\", NS):\n",
    "                text_xmlid = text.attrib.get(\n",
    "                    '{http://www.w3.org/XML/1998/namespace}id', '')\n",
    "\n",
    "                types_all = set()\n",
    "                for segm in text.findall(\".//tei:seg\", NS):\n",
    "                    tn = segm.attrib.get(\n",
    "                        '{www.dglab.uni-jena.de/vmf/a}ana', '')\n",
    "\n",
    "                    tn_list = []\n",
    "                    for x in tn.replace(\";\", \",\").split(\",\"):\n",
    "                        x = x.strip()\n",
    "                        if x.startswith('a'):\n",
    "                            tn_list.append(x)\n",
    "\n",
    "                    types_all.update(tn_list)\n",
    "\n",
    "                # gToDo: this logic should be simplified\n",
    "                # --- Prüfbedingungen ---\n",
    "                if isinstance(typ_input, str):\n",
    "                    # Nur ein einziger Typ erlaubt (keine Kombinationen)\n",
    "                    ok = (types_all == {typ_input})\n",
    "                else:\n",
    "                    ok_and = True\n",
    "                    ok_or = True\n",
    "                    ok_not = True\n",
    "\n",
    "                    if \"AND\" in typ_input:\n",
    "                        ok_and = all(\n",
    "                            t in types_all for t in typ_input[\"AND\"])\n",
    "                    if \"OR\" in typ_input:\n",
    "                        ok_or = any(\n",
    "                            t in types_all for t in typ_input[\"OR\"])\n",
    "                    if \"NOT\" in typ_input:\n",
    "                        ok_not = all(\n",
    "                            t not in types_all for t in typ_input[\"NOT\"])\n",
    "\n",
    "                    # Kombination nach MODE\n",
    "                    if \"AND\" in typ_input and \"OR\" in typ_input:\n",
    "                        if mode == \"OR\":\n",
    "                            ok = (ok_and or ok_or) and ok_not\n",
    "                        else:  # MODE = \"AND\" (Standard)\n",
    "                            ok = (ok_and and ok_or) and ok_not\n",
    "                    elif \"AND\" in typ_input:\n",
    "                        ok = ok_and and ok_not\n",
    "                    elif \"OR\" in typ_input:\n",
    "                        ok = ok_or and ok_not\n",
    "                    else:\n",
    "                        ok = ok_not\n",
    "                if ok:\n",
    "                    textid_to_typ[text_xmlid] = True\n",
    "\n",
    "    # --- Ergebnis als Python-Liste speichern ---\n",
    "    text_ids = sorted(textid_to_typ.keys())\n",
    "\n",
    "    # Speichern der Märchendaten für jedes `text_id`\n",
    "    maerchen_daten = {text_id: [] for text_id in text_ids}\n",
    "\n",
    "    def label_url(lbl):\n",
    "        return f'{{www.dglab.uni-jena.de/vmf/{lbl}}}ana'\n",
    "\n",
    "    for text_id in text_ids:\n",
    "        for ganze in ROOT_NODE.findall(\".//{http://www.tei-c.org/ns/1.0}text\"):\n",
    "            quelle = ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "\n",
    "            if text_id != quelle:\n",
    "                continue\n",
    "            for body in ganze.findall(\".//{http://www.tei-c.org/ns/1.0}body\"):\n",
    "                for absatz in body.findall(\".//{http://www.tei-c.org/ns/1.0}p\"):\n",
    "                    for phrase in absatz.findall(\".//{http://www.tei-c.org/ns/1.0}seg\"):\n",
    "                        if phrase is None:\n",
    "                            continue\n",
    "\n",
    "                        try:\n",
    "                            attrib = phrase.attrib\n",
    "                            text = phrase.text\n",
    "                            if text is None:\n",
    "                                text = \"\"\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "\n",
    "                        labela = attrib[label_url('a')]\n",
    "                        if not labela.startswith('a'):\n",
    "                            continue\n",
    "\n",
    "                        labelbs = []\n",
    "                        labelcs = []\n",
    "                        labelds = []\n",
    "                        for i in range(1, 6):\n",
    "                            labelbs.append(attrib.get(label_url(f'b{i}'), 'N'))\n",
    "                            labelcs.append(attrib.get(label_url(f'c{i}'), 'N'))\n",
    "                            labelds.append(attrib.get(label_url(f'd{i}'), 'N'))\n",
    "\n",
    "                        dana = \"_\".join(labelds).replace(\"_N\", \"\")\n",
    "\n",
    "                        try:\n",
    "                            labeld = sortiere_dana(dana, REFERENZ_LISTE)\n",
    "                        except ValueError:\n",
    "                            labeld = dana\n",
    "\n",
    "                        for lb, lc in zip(labelbs, labelcs):\n",
    "                            \n",
    "                            #include_labeld = False\n",
    "                            if include_labeld:\n",
    "                                row = f\"{labela}:{lb}:{lc}:{labeld}\"\n",
    "                            else:\n",
    "                                row = f\"{labela}:{lb}:{lc}\" \n",
    "                            \n",
    "                            if ':N:' not in row:\n",
    "                                maerchen_daten[text_id].append(row)\n",
    "\n",
    "    unique_values_per_text_id = {}\n",
    "    result_data_per_ch = {}\n",
    "    gesamt_ergebnisse = {}\n",
    "\n",
    "    for text_id, filtered_data in maerchen_daten.items():\n",
    "        # Duplikate erkennen und kennzeichnen\n",
    "        seen = {}\n",
    "        for i, line in enumerate(filtered_data):\n",
    "            if line not in seen:\n",
    "                seen[line] = 0\n",
    "            else:\n",
    "                seen[line] += 1\n",
    "                suffix = \"_+\" * seen[line]\n",
    "                filtered_data[i] = f\"{line}{suffix}\"\n",
    "\n",
    "        # Eindeutige Werte extrahieren\n",
    "        unique_values = (line.split(':')[0] for line in filtered_data)\n",
    "        unique_values_per_text_id[text_id] = unique_values\n",
    "        result_data_per_ch[text_id] = filtered_data\n",
    "        gesamt_ergebnisse[text_id] = filtered_data\n",
    "\n",
    "    zeilen_counter = Counter()\n",
    "    # Alle TXT-Dateien im Ordner durchgehen\n",
    "    for lines in gesamt_ergebnisse.values():\n",
    "        for line in lines:\n",
    "            z = line.strip()\n",
    "            if z:\n",
    "                zeilen_counter[z] += 1\n",
    "\n",
    "    # Zeilen, die mindestens min_counts-mal vorkommen\n",
    "    eindeutige_zeilen: set = {zeile for zeile,\n",
    "                              count in zeilen_counter.items() if count >= min_count}\n",
    "\n",
    "    return gesamt_ergebnisse, eindeutige_zeilen, text_ids\n",
    "\n",
    "\n",
    "# --- Paarweise Stimmen sammeln ---\n",
    "def collect_pair_votes(base_lines, gesamt_ergebnisse):\n",
    "\n",
    "    votes = defaultdict(int)\n",
    "    base_set = set(base_lines)\n",
    "    for lines in gesamt_ergebnisse.values():\n",
    "        lines = [line for line in lines if line in base_set]\n",
    "        for i in range(len(lines)):\n",
    "            for j in range(i+1, len(lines)):\n",
    "                a, b = lines[i], lines[j]\n",
    "                votes[(a, b)] += 1\n",
    "\n",
    "    return votes\n",
    "\n",
    "# --- Mehrheitsgraph bauen ---\n",
    "def build_majority_graph(base_lines, votes):\n",
    "    graph = defaultdict(set)\n",
    "    indegree = {line: 0 for line in base_lines}\n",
    "    used_nodes = set()\n",
    "    for (a, b), count in votes.items():\n",
    "        reverse_count = votes.get((b, a), 0)\n",
    "        if count > reverse_count:\n",
    "            if b not in graph[a]:\n",
    "                graph[a].add(b)\n",
    "                indegree[b] += 1\n",
    "                used_nodes.update([a, b])\n",
    "        elif reverse_count > count:\n",
    "            if a not in graph[b]:\n",
    "                graph[b].add(a)\n",
    "                indegree[a] += 1\n",
    "                used_nodes.update([a, b])\n",
    "    return graph, indegree, used_nodes\n",
    "\n",
    "# --- Topologische Sortierung ---\n",
    "def topo_sort(graph, indegree, used_nodes):\n",
    "    queue = deque([n for n in used_nodes if indegree[n] == 0])\n",
    "    result = []\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        if node not in result:\n",
    "            result.append(node)\n",
    "        for neighbor in graph[node]:\n",
    "            indegree[neighbor] -= 1\n",
    "            if indegree[neighbor] == 0:\n",
    "                queue.append(neighbor)\n",
    "    return result\n",
    "\n",
    "# --- Basisdatei sortieren ---\n",
    "def sort_base(eindeutige_zeilen, gesamt_ergebnisse):\n",
    "\n",
    "    votes = collect_pair_votes(\n",
    "        eindeutige_zeilen, gesamt_ergebnisse)\n",
    "\n",
    "    graph, indegree, used_nodes = build_majority_graph(\n",
    "        eindeutige_zeilen, votes)\n",
    "\n",
    "    sorted_lines = topo_sort(graph, indegree, used_nodes)\n",
    "\n",
    "    # Nicht verwendete Zeilen hinten anhängen + markieren\n",
    "    for line in eindeutige_zeilen:\n",
    "        if line not in sorted_lines:\n",
    "            marked_line = f\"*{line}\"\n",
    "            sorted_lines.append(marked_line)\n",
    "\n",
    "    return sorted_lines\n",
    "\n",
    "# --- Hauptprogramm ---\n",
    "def grundform(data):\n",
    "\n",
    "    min_count = int(data[\"min_count\"])\n",
    "    gesamt_ergebnisse, eindeutige_zeilen, text_ids = eindeutige_zeilen_erstellen(\n",
    "        **data)\n",
    "\n",
    "    # Sortierung nach Mehrheitsregeln\n",
    "    sorted_lines = sort_base(sorted(eindeutige_zeilen), gesamt_ergebnisse)\n",
    "\n",
    "    zeilen = []\n",
    "    for i in range(0, len(text_ids), 3):\n",
    "        zeilen.append(\"\\t\".join(f\"'{w}'\" for w in text_ids[i:i+3]))\n",
    "\n",
    "    typ_formatiert = json.dumps(json.loads(data[\"typ_input\"]))\n",
    "    output_text = f'Typ(en) = {typ_formatiert}'\n",
    "    output_text += \"\\n\"\n",
    "    output_text += f\"Häufigkeit = {min_count}\"\n",
    "    output_text += \"\\n\"\n",
    "    output_text += \"Text-IDs:\"\n",
    "    output_text += \"\\n\"\n",
    "    output_text += \"\\n\".join(zeilen)\n",
    "    output_text += \"\\n---------------------\\n\"\n",
    "\n",
    "    for line in sorted_lines:\n",
    "        if line.startswith(\"*\"):\n",
    "            output_text += f\"{line}\\n\"\n",
    "        else:\n",
    "            output_text += f\"{line}\\n\"\n",
    "\n",
    "    return output_text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {\n",
    "        \"xml_database_name\":datei,\n",
    "        \"typ_input\": gesuchter_typ,\n",
    "        \"min_count\": haeufigkeit\n",
    "    }\n",
    "\n",
    "    gf = grundform(config)\n",
    "    print(gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8bce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78217de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
