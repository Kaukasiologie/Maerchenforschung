{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c98aab2f",
   "metadata": {},
   "source": [
    "# erthaos-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b11808-398e-44c9-9506-aa55701f9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistent für die automatische Erkennung der gesuchten Motive\n",
    "\n",
    "\"\"\"\n",
    "PARAM_label_1 = \"\" : Die Abfragewerte für das Zielmotiv mit entsprechende Label.\n",
    "                        Die Werte von 'gesuchte_episoden können nach der in der\n",
    "                        Motivliste ausgewälte Zeilen, oder ihre Bestandteilen ausgefült\n",
    "                        werden und anschließend in der Anfragezeile als Anfrage mit\n",
    "                        'or' und/oder 'and' Opperatoren bestimmen.\n",
    "\n",
    "Stoppwortliste für die bestimmte Sprache.\n",
    "\"\"\"\n",
    "\n",
    "from io import StringIO\n",
    "from matplotlib import text\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import csv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import xml.etree.ElementTree as ET\n",
    "import mglearn\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from hilfsfunktoinen import lade_referenz_liste_aus_xsd, parse_xml\n",
    "from hilfsfunktoinen import find_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92bbb86-f915-4816-911a-094f243a3de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_XML_DATABASE_NAME = 'test.xml'\n",
    "ROOT_NODE = ET.parse(PARAM_XML_DATABASE_NAME).getroot()\n",
    "NS = {'tei': 'http://www.tei-c.org/ns/1.0'} # 3 Namespace definieren\n",
    "REFERENZ_LISTE = lade_referenz_liste_aus_xsd(\"kf/vmf_d1.xsd\")  # passe den Pfad an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2eef72-20b6-4c7a-8d42-9bc12ffd8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV datensatz erstellen\n",
    "\n",
    "# xml datei parsen\n",
    "maerchen = parse_xml(ROOT_NODE, NS, REFERENZ_LISTE, parse_labels=True)\n",
    "# xml header und ballast einfuegen\n",
    "maerchen_header = 'quelle,index_string,inhalt,index_binar'\n",
    "maerchen = f'{maerchen_header}\\n{maerchen}'\n",
    "\n",
    "# data frame erstellen \n",
    "df_maerchen = pd.read_csv(StringIO(maerchen)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256245e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern = r'(?<=:)(?=a)'\n",
    "indexliste = Counter(\n",
    "    part\n",
    "    for s in df_maerchen.index_string\n",
    "    for part in re.split(pattern, s)\n",
    ")\n",
    "print(*indexliste, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c4abe6-4425-4158-889c-e722b3452740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nach dem Label suchen\n",
    "\n",
    "PARAM_label_1 = \":Menschliche_OPFERGABE_beheben:\"\n",
    "PARAM_label_2 = \"\"\n",
    "PARAM_label_3 = \"\"\n",
    "\n",
    "for idx, gesuchte_label in zip(df_maerchen.index, df_maerchen.index_string):\n",
    "    if PARAM_label_1 in gesuchte_label:# or PARAM_label_2 in gesuchte_label:# and PARAM_label_3 in gesuchte_label:\n",
    "        print(f\" {gesuchte_label}\")\n",
    "        df_maerchen.loc[idx, 'index_binar'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ccec89-5a9c-4166-b8e0-7e15dd5f280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nicht gewollte label a in Aggregation eliminieren\n",
    "\n",
    "# Datensätzen die diesen a Wert nicht haben aber b und/oder c Werte besitzen können,\n",
    "# werden aus der Aggregatiodatei eliminiert. Dadurch wird es verhindert, dass die Datensetzen mit\n",
    "# gleichen Inhalte nicht als negative Werte entgegengesetzt werden.\n",
    "\n",
    "PARAM_elim = \"a300\"\n",
    "df_maerchen = df_maerchen[~((df_maerchen['index_binar'] == 1) & (~df_maerchen['index_string'].str.contains(PARAM_elim, na=False)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23932e-7680-42f4-8ec8-b11243b2cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste Trainingsrunde\n",
    "\n",
    "X_train = df_maerchen.inhalt  # Inhalt der Texte\n",
    "y_train = df_maerchen.index_binar  # Binäre Indikatoren\n",
    "\n",
    "# Zählen der Vorkommen jeder Binärklasse in der Spalte 'index_binar'\n",
    "indexliste = Counter(df_maerchen.index_binar)\n",
    "\n",
    "# Ausgabe der Anzahl der Vorkommen jeder Binärklasse\n",
    "print(indexliste)\n",
    "\n",
    "# NaN-Werte entfernen / ersetzen\n",
    "X_train = X_train.fillna(\"\")\n",
    "PARAM_NGRAMM_RANGE = (1, 1)\n",
    "PARAM_MIN_DF = 2\n",
    "\n",
    "PARAM_USE_STOPWORDS = True\n",
    "custom_stop_word_list = ['graf','grafen']\n",
    "\n",
    "if PARAM_USE_STOPWORDS:\n",
    "    nltk.download('stopwords')\n",
    "    nltk_stop_words_list = nltk.corpus.stopwords.words('german')\n",
    "    custom_stop_word_list = custom_stop_word_list + nltk_stop_words_list\n",
    "\n",
    "# create the machine learning pipelines\n",
    "pipe = make_pipeline(\n",
    "    TfidfVectorizer(min_df=PARAM_MIN_DF, stop_words=custom_stop_word_list, ngram_range=PARAM_NGRAMM_RANGE, norm=None),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "perform_regularization_sweep = False\n",
    "if perform_regularization_sweep:\n",
    "    param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Bester Score aus der Kreuzvalidierung: {:.2f}\".format(grid.best_score_))\n",
    "    estimator = grid.best_estimator_\n",
    "else:\n",
    "    pipe.fit(X_train, y_train)\n",
    "    estimator = pipe\n",
    "\n",
    "# Extrahieren des TF-IDF-Vektorisierers aus dem besten Schätzschritt des Gittersuchlaufs\n",
    "vectorizer = estimator.named_steps[\"tfidfvectorizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107cd77-b4fe-4c24-9222-edf89c7755df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ermitteln des maximalen TF-IDF-Werts für jedes Merkmal\n",
    "max_value = vectorizer.transform(X_train).max(axis=0).toarray().ravel()\n",
    "\n",
    "# Sortieren der Merkmale nach ihren TF-IDF-Werten\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "\n",
    "# Extrahieren der Merkmalsnamen aus dem Vektorisierer\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "print(\"Gesamte Anzahl der Merkmale: {}\".format(len(vectorizer.vocabulary_)))\n",
    "\n",
    "# Alle Koeffizienten\n",
    "coefficients = estimator.named_steps[\"logisticregression\"].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348829a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# größter Koeffizient\n",
    "max_coef = np.max(coefficients)\n",
    "\n",
    "# Der Schwellenwert (30% empfohlen)\n",
    "threshold = 0.3 * max_coef\n",
    "\n",
    "# Positionen (Indizes), die >= Schwellenwert sind\n",
    "sw_position = np.where(coefficients >= threshold)[0]\n",
    "\n",
    "# Zugehörige Feature-Namen und Koeffizienten\n",
    "sw_features = feature_names[sw_position]\n",
    "sw_coefs = coefficients[sw_position]\n",
    "\n",
    "# Indizes für absteigende Sortierung der Koeffizienten\n",
    "sort_idx = np.argsort(sw_coefs)[::-1]  # ::-1 dreht die Reihenfolge um\n",
    "\n",
    "# Absteigend sortierte Features und Koeffizienten\n",
    "sw_features_sorted = sw_features[sort_idx]\n",
    "sw_coefs_sorted = sw_coefs[sort_idx]\n",
    "\n",
    "# Ausgabe nummeriert ohne Anführungszeichen\n",
    "\n",
    "for i, feature in enumerate(sw_features_sorted):\n",
    "    print(f\"{i}. {feature}  ({sw_coefs_sorted[i]:.4f})\")\n",
    "    selected_features_text = \" \".join({feature})\n",
    "    \n",
    "selected_features = []\n",
    "\n",
    "for feature in sw_features_sorted:\n",
    "    selected_features.append(feature)\n",
    "selected_features_text = \" \".join(selected_features)\n",
    "# print(selected_features_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maerchen_nicht_gelabelt = parse_xml(ROOT_NODE, NS, REFERENZ_LISTE, parse_labels=False)\n",
    "maerchen_nicht_gelabelt_header = 'quelle,inhalt,index_binar'\n",
    "maerchen_nicht_gelabelt = f'{maerchen_nicht_gelabelt_header}\\n{maerchen_nicht_gelabelt}'\n",
    "df_maerchen_nicht_gelabelt = pd.read_csv(StringIO(maerchen_nicht_gelabelt)).dropna()\n",
    "df_maerchen_nicht_gelabelt = df_maerchen_nicht_gelabelt.sort_values('inhalt')\n",
    "\n",
    "df_maerchen_nicht_gelabelt = df_maerchen_nicht_gelabelt[~(df_maerchen_nicht_gelabelt['inhalt'] == '')]\n",
    "\n",
    "t_corpus = df_maerchen_nicht_gelabelt['inhalt'].to_list()\n",
    "t_corpus.append(selected_features_text)\n",
    "\n",
    "all_coef_vector_unlabeled = vectorizer.fit_transform(t_corpus)\n",
    "\n",
    "model_vector_unlabeled = all_coef_vector_unlabeled[-1]\n",
    "result_coefs = all_coef_vector_unlabeled[:-1]\n",
    "\n",
    "sorted_index_unlabeled, sorted_similarities_unlabeled = find_similar(model_vector_unlabeled, result_coefs)\n",
    "sorted_similarities_unlabeled = np.round(sorted_similarities_unlabeled, 5)\n",
    "\n",
    "for i, (bewertung, quelle, inhalt) in enumerate(\n",
    "    zip(\n",
    "        sorted_similarities_unlabeled,\n",
    "        df_maerchen_nicht_gelabelt['quelle'].iloc[sorted_index_unlabeled],\n",
    "        df_maerchen_nicht_gelabelt['inhalt'].iloc[sorted_index_unlabeled]\n",
    "    )\n",
    "):\n",
    "    print(f'{np.round(bewertung,4):9} || {quelle} || {inhalt}\\n')\n",
    "    if i > 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c23ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
